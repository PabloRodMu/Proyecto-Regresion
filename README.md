# üöó Predicci√≥n de Precios de Veh√≠culos Usados

> **Proyecto de Machine Learning para la estimaci√≥n del valor de mercado de autom√≥viles de segunda mano mediante modelos de regresi√≥n avanzados**

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![Docker](https://img.shields.io/badge/Docker-Ready-brightgreen.svg)](https://www.docker.com/)
[![XGBoost](https://img.shields.io/badge/XGBoost-Model-orange.svg)](https://xgboost.readthedocs.io/)

---

## üìã Tabla de Contenidos

- [Descripci√≥n General del Proyecto](#-descripci√≥n-general-del-proyecto)
- [Contexto del Negocio](#-contexto-del-negocio)
- [Objetivos del Proyecto](#-objetivos-del-proyecto)
- [Equipo de Trabajo](#-equipo-de-trabajo)
- [Tecnolog√≠as Utilizadas](#Ô∏è-tecnolog√≠as-utilizadas)
- [Estructura del Repositorio](#-estructura-del-repositorio)
- [Dataset y Variables](#-dataset-y-variables)
- [Limpieza de Datos y EDA](#-limpieza-de-datos-y-eda)
- [Feature Engineering](#-feature-engineering)
- [Modelado y Entrenamiento](#-modelado-y-entrenamiento)
- [Dashboard Interactivo](#-dashboard-interactivo)
- [Dockerizaci√≥n](#-dockerizaci√≥n)
- [Instalaci√≥n y Ejecuci√≥n](#-instalaci√≥n-y-ejecuci√≥n)
- [Resultados y Conclusiones](#-resultados-y-conclusiones)
- [Mejoras Futuras](#-mejoras-futuras)
- [Referencias](#-referencias)

---

## üéØ Descripci√≥n General del Proyecto

Este proyecto desarrolla un **sistema completo de Machine Learning** para predecir el precio de veh√≠culos usados en el mercado estadounidense. Combina an√°lisis exploratorio de datos (EDA), ingenier√≠a de caracter√≠sticas, modelado predictivo con algoritmos avanzados de regresi√≥n y una interfaz web interactiva para visualizaci√≥n y predicci√≥n en tiempo real.

El proyecto aborda el desaf√≠o de estimar con precisi√≥n el valor de mercado de autom√≥viles considerando m√∫ltiples factores como marca, modelo, a√±o, kilometraje, caracter√≠sticas del motor y condici√≥n del veh√≠culo. La soluci√≥n implementada utiliza **XGBoost**, uno de los algoritmos m√°s potentes para problemas de regresi√≥n, logrando un **R¬≤ de 0.66** con un control riguroso del sobreajuste.

---

## üíº Contexto del Negocio

### El Problema

El mercado de veh√≠culos usados mueve miles de millones de d√≥lares anualmente, pero la **valoraci√≥n precisa de veh√≠culos** representa un desaf√≠o tanto para vendedores como compradores:

- **Vendedores individuales** no saben c√≥mo fijar un precio competitivo
- **Concesionarios** necesitan evaluar r√°pidamente el valor de intercambio
- **Compradores** requieren herramientas para identificar ofertas justas
- **Plataformas online** buscan automatizar la tasaci√≥n para mejorar la experiencia del usuario

### La Soluci√≥n

Un modelo predictivo basado en datos hist√≥ricos que:

1. **Analiza patrones** en +188,000 transacciones reales de veh√≠culos
2. **Identifica factores clave** que determinan el precio de mercado
3. **Predice valores** con un margen de error controlado
4. **Proporciona transparencia** mediante visualizaciones interactivas

### Valor de Negocio

- ‚úÖ **Automatizaci√≥n** de tasaciones que tradicionalmente requieren expertos
- ‚úÖ **Reducci√≥n de tiempo** en la valoraci√≥n de inventario
- ‚úÖ **Mejora de confianza** del usuario mediante predicciones basadas en datos
- ‚úÖ **Optimizaci√≥n de precios** para maximizar ventas y satisfacci√≥n del cliente

---

## üéØ Objetivos del Proyecto

### Objetivo Principal

Desarrollar un **modelo de regresi√≥n robusto y generalizable** capaz de predecir el precio de veh√≠culos usados con alta precisi√≥n (R¬≤ > 0.60) y bajo sobreajuste (overfitting < 5%), utilizando caracter√≠sticas extra√≠bles de anuncios de venta est√°ndar.

### Objetivos Secundarios

1. **An√°lisis Exploratorio Exhaustivo**
   - Identificar patrones y relaciones en los datos
   - Detectar y tratar valores at√≠picos
   - Entender la distribuci√≥n de precios y su relaci√≥n con variables predictoras

2. **Feature Engineering Efectivo**
   - Extraer caracter√≠sticas num√©ricas del campo `engine` (caballos de fuerza, litros)
   - Implementar codificaci√≥n robusta para variables categ√≥ricas de alta cardinalidad
   - Crear variables derivadas que mejoren el poder predictivo

3. **Comparaci√≥n de Modelos**
   - Evaluar m√∫ltiples algoritmos (Regresi√≥n Lineal, Random Forest, Gradient Boosting, XGBoost)
   - Optimizar hiperpar√°metros mediante GridSearchCV
   - Seleccionar el modelo con mejor balance entre rendimiento y generalizaci√≥n

4. **Desarrollo de Aplicaci√≥n Interactiva**
   - Dashboard anal√≠tico con KPIs y visualizaciones clave
   - Interfaz de predicci√≥n en tiempo real
   - M√©tricas de rendimiento del modelo transparentes para el usuario

5. **Despliegue Reproducible**
   - Dockerizaci√≥n completa del proyecto
   - Documentaci√≥n clara para instalaci√≥n y ejecuci√≥n
   - C√≥digo modular y mantenible

---

## üë• Equipo de Trabajo

Este proyecto fue desarrollado colaborativamente por un equipo multidisciplinario durante el Bootcamp de Data Analysis de Factor√≠a F5:

| Rol | Nombre | GitHub | LinkedIn |
|-----|--------|--------|----------|
| **Product Owner** | Ra√∫l R√≠os Moreno | [@RayalzDev](https://github.com/RayalzDev) | [LinkedIn](https://www.linkedin.com/in/raul-rios-moreno/) |
| **Data Analyst** | Pablo Rodr√≠guez Mu√±oz | [@PabloRodMu](https://github.com/PabloRodMu) | [LinkedIn](https://www.linkedin.com/in/pablo-rodr√≠guez-mu√±oz-357890185) |
| **Scrum Master** | Mariana Moreno | [@MarianaMH1195](https://github.com/MarianaMH1195) | [LinkedIn](https://www.linkedin.com/in/mariana-moreno-henao/) |

**Metodolog√≠a**: Scrum con sprints semanales, daily standups virtuales y pair programming para secciones cr√≠ticas del c√≥digo.

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Lenguajes y Frameworks

- **Python 3.10**: Lenguaje principal de desarrollo
- **Streamlit**: Framework para la aplicaci√≥n web interactiva
- **Docker**: Containerizaci√≥n para despliegue reproducible

### Librer√≠as de Data Science y Machine Learning

| Categor√≠a | Librer√≠as |
|-----------|-----------|
| **Manipulaci√≥n de Datos** | `pandas`, `numpy` |
| **Visualizaci√≥n** | `matplotlib`, `seaborn`, `plotly` |
| **Machine Learning** | `scikit-learn`, `xgboost` |
| **Persistencia** | `joblib` |
| **Utilidades** | `json` (m√©tricas) |

### Algoritmos de ML Evaluados

1. **Linear Regression** - Baseline model
2. **Random Forest Regressor** - Ensemble basado en √°rboles
3. **Gradient Boosting Regressor** - Boosting secuencial
4. **XGBoost** ‚≠ê - **Modelo final seleccionado**

### Herramientas de Desarrollo

- **Google Colab**: Desarrollo y experimentaci√≥n de notebooks
- **Git/GitHub**: Control de versiones
- **Docker Compose**: Orquestaci√≥n de servicios

---

## üìÇ Estructura del Repositorio

```
Proyecto-Regression-g1/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                          # Datos originales sin procesar
‚îÇ   ‚îî‚îÄ‚îÄ clean/
‚îÇ       ‚îî‚îÄ‚îÄ train_ready_for_modeling.csv  # Dataset procesado para modelado
‚îÇ
‚îú‚îÄ‚îÄ model/                            # Modelos y artefactos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ best_xgb_model_final.pkl      # Modelo XGBoost optimizado
‚îÇ   ‚îú‚îÄ‚îÄ target_encoding_maps.joblib   # Mapeos de target encoding
‚îÇ   ‚îú‚îÄ‚îÄ feature_order.pkl             # Orden de features para predicci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ brand_model_options.pkl       # Opciones v√°lidas de marca/modelo
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda_data_analysis.ipynb    # An√°lisis exploratorio de datos
‚îÇ   ‚îî‚îÄ‚îÄ modeling_and_validation.ipynb # Entrenamiento y evaluaci√≥n de modelos
‚îÇ
‚îú‚îÄ‚îÄ App.py                            # Aplicaci√≥n Streamlit principal
‚îú‚îÄ‚îÄ metrics.json                      # M√©tricas del modelo final
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile                        # Configuraci√≥n de imagen Docker
‚îú‚îÄ‚îÄ docker-compose.yml                # Orquestaci√≥n de contenedor
‚îú‚îÄ‚îÄ requirements.txt                  # Dependencias Python
‚îú‚îÄ‚îÄ .dockerignore                     # Archivos excluidos de build
‚îÇ
‚îî‚îÄ‚îÄ README.md                         # Documentaci√≥n del proyecto
```

### Descripci√≥n de Archivos Clave

- **`App.py`**: Punto de entrada de la aplicaci√≥n web con tres secciones principales (Dashboard, Predicci√≥n, Rendimiento)
- **`metrics.json`**: Almacena RMSE, MAE, R¬≤ del modelo para visualizaci√≥n en el dashboard
- **`best_xgb_model_final.pkl`**: Modelo XGBoost serializado con hiperpar√°metros optimizados
- **`target_encoding_maps.joblib`**: Diccionarios de codificaci√≥n para variables categ√≥ricas de alta cardinalidad
- **`brand_model_options.pkl`**: Estructura anidada que define opciones v√°lidas de marca ‚Üí modelo ‚Üí colores

---

## üìä Dataset y Variables

### Origen del Dataset

El dataset proviene de **Kaggle** y contiene informaci√≥n real de anuncios de veh√≠culos usados en el mercado estadounidense.

### Dimensiones

- **Conjunto de Entrenamiento**: 188,533 registros √ó 13 columnas
- **Conjunto de Prueba**: 125,690 registros √ó 12 columnas (sin variable objetivo)

### Variables Originales

| Variable | Tipo | Descripci√≥n | Ejemplo |
|----------|------|-------------|---------|
| `id` | int | Identificador √∫nico del veh√≠culo | 0, 1, 2... |
| `brand` | str | Marca del fabricante | "Toyota", "Ford", "BMW" |
| `model` | str | Modelo espec√≠fico | "Camry", "F-150", "X5" |
| `model_year` | int | A√±o de fabricaci√≥n | 2015, 2020 |
| `milage` | int | Kilometraje (millas) | 50000, 120000 |
| `fuel_type` | str | Tipo de combustible | "Gasoline", "Hybrid", "E85 Flex Fuel" |
| `engine` | str | Especificaciones del motor | "200.0HP 2.5L 4 Cylinder Engine Gasoline Fuel" |
| `transmission` | str | Tipo de transmisi√≥n | "A/T", "M/T", "CVT" |
| `ext_col` | str | Color exterior | "White", "Black", "Silver" |
| `int_col` | str | Color interior | "Black", "Beige", "Gray" |
| `accident` | str | Historial de accidentes | "None reported", "At least 1 accident..." |
| `clean_title` | str | Estado del t√≠tulo | "Yes", "No" |
| **`price`** | **int** | **Variable objetivo (precio en USD)** | **25000, 45000** |

### Caracter√≠sticas del Precio (Variable Objetivo)

- **Rango**: $1,000 - $3,000,000+
- **Media**: ~$32,000
- **Mediana**: ~$27,000
- **Distribuci√≥n**: Sesgada a la derecha (presencia de veh√≠culos de lujo de alto valor)

---

## üßπ Limpieza de Datos y EDA

### Proceso de Limpieza

El notebook `01_eda_data_analysis.ipynb` implementa un pipeline de limpieza riguroso:

#### 1. **Carga de Datos**
```python
import pandas as pd
df_train = pd.read_csv("train.csv")
df_test = pd.read_csv("test.csv")
```

#### 2. **An√°lisis de Valores Nulos**
- **Hallazgo**: Valores nulos detectados principalmente en `ext_col` e `int_col`
- **Tratamiento**: Imputaci√≥n con categor√≠a "Unknown" o eliminaci√≥n seg√∫n % de nulos

#### 3. **Detecci√≥n de Duplicados**
- **Verificaci√≥n**: Identificaci√≥n de registros duplicados por `id`
- **Acci√≥n**: Eliminaci√≥n de duplicados manteniendo primera ocurrencia

#### 4. **Conversi√≥n de Tipos de Datos**
- **Variables categ√≥ricas**: Conversi√≥n a tipo `category` para optimizaci√≥n de memoria
- **Variables booleanas**: Creaci√≥n a partir de variables binarias (`clean_title_Yes`)

#### 5. **An√°lisis de Outliers**
- **Precio**: Identificaci√≥n de valores extremos (>$500,000) mediante visualizaci√≥n de boxplot
- **Kilometraje**: Detecci√≥n de valores an√≥malos (>500,000 millas)
- **Decisi√≥n**: Mantenimiento de outliers reales (veh√≠culos de lujo) vs eliminaci√≥n de errores de captura

### An√°lisis Exploratorio de Datos (EDA)

#### KPIs Principales

| M√©trica | Valor | Insight |
|---------|-------|---------|
| **Precio Medio** | $32,145 | Indica el segmento de mercado predominante (gama media) |
| **Precio Mediano** | $27,500 | Diferencia con la media sugiere distribuci√≥n sesgada |
| **Desviaci√≥n Est√°ndar** | $21,893 | Alta variabilidad en precios, requiere modelo robusto |
| **N¬∞ Veh√≠culos** | 188,533 | Dataset suficientemente grande para ML |

#### Visualizaciones Clave y Sus Insights

##### 1. **Distribuci√≥n de Precios**
```python
plt.hist(df[df['price'] < 300000]['price'], bins=50)
plt.xlabel('Precio ($)')
plt.ylabel('Frecuencia')
```
**Insight**: 
- **Distribuci√≥n sesgada a la derecha** con concentraci√≥n en el rango $10,000-$40,000
- Presencia de **cola larga** hacia precios elevados (veh√≠culos de lujo/colecci√≥n)
- Sugiere aplicar **transformaci√≥n logar√≠tmica** para normalizar la distribuci√≥n en el modelo

##### 2. **Kilometraje vs Precio**
```python
plt.scatter(df['milage'], df['price'], alpha=0.3)
```
**Insight**:
- **Correlaci√≥n negativa clara**: A mayor kilometraje, menor precio (depreciaci√≥n)
- Relaci√≥n **no lineal** en extremos (veh√≠culos con muy bajo kilometraje mantienen precio premium)
- Variable **altamente predictiva** para el modelo

##### 3. **A√±o del Modelo vs Precio**
```python
plt.scatter(df['model_year'], df['price'], alpha=0.3)
```
**Insight**:
- **Correlaci√≥n positiva fuerte**: Veh√≠culos m√°s nuevos tienen precios significativamente mayores
- Modelos posteriores a 2015 muestran **mayor dispersi√≥n** (amplia variedad de marcas/modelos)
- Variable **cr√≠tica** para predicci√≥n precisa

##### 4. **Boxplot de Precios por Marca**
**Insight**:
- Marcas de **lujo** (Mercedes-Benz, BMW, Audi) presentan medianas significativamente superiores
- **Alta variabilidad** dentro de marcas populares (Toyota, Ford) debido a diversidad de modelos
- Justifica uso de **target encoding** para capturar el efecto marca-modelo

##### 5. **Distribuci√≥n de Tipos de Combustible**
**Insight**:
- **Dominio de gasolina** (~75% del dataset)
- Veh√≠culos **h√≠bridos/el√©ctricos** representan segmento creciente pero minoritario
- Requiere **one-hot encoding** para capturar efecto en precio

### Conclusiones del EDA

1. **Variables m√°s influyentes**: `model_year`, `milage`, `brand`, `model`, caracter√≠sticas del motor
2. **Transformaciones necesarias**: Log-transform del precio, escalado de variables num√©ricas
3. **Encoding requerido**: Target encoding para `brand`/`model`, One-Hot para `fuel_type`/`accident`
4. **Desaf√≠os identificados**: Alta cardinalidad en `brand` √ó `model`, presencia de outliers leg√≠timos

---

## üîß Feature Engineering

### Extracci√≥n de Caracter√≠sticas del Motor

El campo `engine` conten√≠a informaci√≥n valiosa en formato string que requer√≠a parsing:

```python
# Ejemplo de registro: "252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel"

def extract_horsepower(engine_str):
    """Extrae caballos de fuerza del string engine"""
    match = re.search(r'(\d+\.?\d*)HP', engine_str)
    return float(match.group(1)) if match else np.nan

def extract_engine_liters(engine_str):
    """Extrae litros del motor del string engine"""
    match = re.search(r'(\d+\.?\d*)L', engine_str)
    return float(match.group(1)) if match else np.nan

df['horsepower'] = df['engine'].apply(extract_horsepower)
df['engine_liters'] = df['engine'].apply(extract_engine_liters)
```

**Resultado**: Dos nuevas features num√©ricas altamente correlacionadas con precio:
- `horsepower`: 50-1500 HP
- `engine_liters`: 0.8-8.0 L

### Encoding de Variables Categ√≥ricas

#### 1. **One-Hot Encoding** (Variables de Baja Cardinalidad)

Aplicado a variables con <10 categor√≠as √∫nicas:

```python
df = pd.get_dummies(df, columns=['fuel_type', 'accident', 'clean_title'], 
                    drop_first=False, dtype=bool)
```

**Variables transformadas**:
- `fuel_type` ‚Üí `fuel_type_Gasoline`, `fuel_type_Hybrid`, `fuel_type_E85 Flex Fuel`, etc.
- `accident` ‚Üí `accident_None reported`
- `clean_title` ‚Üí `clean_title_Yes`

#### 2. **Target Encoding** (Variables de Alta Cardinalidad)

Para `brand`, `model`, `ext_col`, `int_col` (cientos de categor√≠as √∫nicas):

```python
def target_encode(df, column, target='price'):
    """
    Codifica variable categ√≥rica con la media del target por categor√≠a
    Incluye smoothing para categor√≠as con pocas observaciones
    """
    encoding_map = df.groupby(column)[target].mean().to_dict()
    global_mean = df[target].mean()
    
    # Smoothing: m = 10 (par√°metro de regularizaci√≥n)
    counts = df[column].value_counts()
    smoothed_map = {}
    for category, mean_price in encoding_map.items():
        count = counts[category]
        smoothed_map[category] = (count * mean_price + 10 * global_mean) / (count + 10)
    
    return smoothed_map, global_mean

# Aplicaci√≥n
brand_map, brand_global = target_encode(df_train, 'brand')
df_train['brand'] = df_train['brand'].map(brand_map)
```

**Ventajas**:
- ‚úÖ Captura relaci√≥n directa entre categor√≠a y precio
- ‚úÖ Reduce dimensionalidad (1 columna num√©rica vs 300+ columnas one-hot)
- ‚úÖ Smoothing evita overfitting en categor√≠as raras

**Guardado de Mapeos**:
```python
joblib.dump({
    'brand': {'mapping': brand_map, 'global_mean': brand_global},
    'model': {'mapping': model_map, 'global_mean': model_global},
    'ext_col': {'mapping': ext_map, 'global_mean': ext_global},
    'int_col': {'mapping': int_map, 'global_mean': int_global}
}, 'target_encoding_maps.joblib')
```

### Features Finales para Modelado

| Feature | Tipo | Transformaci√≥n |
|---------|------|----------------|
| `brand` | Num√©rica | Target Encoding |
| `model` | Num√©rica | Target Encoding |
| `model_year` | Num√©rica | Sin transformaci√≥n |
| `milage` | Num√©rica | Sin transformaci√≥n |
| `horsepower` | Num√©rica | Extra√≠da de `engine` |
| `engine_liters` | Num√©rica | Extra√≠da de `engine` |
| `ext_col` | Num√©rica | Target Encoding |
| `int_col` | Num√©rica | Target Encoding |
| `turbo` | Booleana | Extra√≠da de `engine` |
| `fuel_type_*` | Booleana | One-Hot Encoding (7 columnas) |
| `accident_None reported` | Booleana | One-Hot Encoding |
| `clean_title_Yes` | Booleana | One-Hot Encoding |

**Total**: 19 features num√©ricas/booleanas

---

## ü§ñ Modelado y Entrenamiento

### Divisi√≥n Train/Test

```python
from sklearn.model_selection import train_test_split

X = df.drop(columns=['price'])
y = np.log1p(df['price'])  # Transformaci√≥n logar√≠tmica del target

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

**Decisi√≥n clave**: **Transformaci√≥n logar√≠tmica** del precio para:
- Normalizar distribuci√≥n sesgada
- Reducir impacto de outliers
- Mejorar homogeneidad de residuos

### Modelos Evaluados

#### 1. **Linear Regression** (Baseline)
```python
from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(X_train, y_train)
```
**Resultados**: 
- RMSE Train: 0.58
- RMSE Test: 0.59
- R¬≤: 0.52
- **Conclusi√≥n**: Modelo simple, √∫til como baseline pero insuficiente para capturar no linealidades

#### 2. **Random Forest Regressor**
```python
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(
    n_estimators=100,
    max_depth=20,
    min_samples_split=10,
    random_state=42
)
rf.fit(X_train, y_train)
```
**Resultados**:
- RMSE Train: 0.41
- RMSE Test: 0.53
- R¬≤: 0.60
- **Conclusi√≥n**: Mejor que baseline, pero presenta overfitting moderado (12% diferencia RMSE)

#### 3. **Gradient Boosting Regressor**
```python
from sklearn.ensemble import GradientBoostingRegressor

gb = GradientBoostingRegressor(
    n_estimators=200,
    learning_rate=0.1,
    max_depth=5,
    random_state=42
)
gb.fit(X_train, y_train)
```
**Resultados**:
- RMSE Train: 0.45
- RMSE Test: 0.50
- R¬≤: 0.63
- **Conclusi√≥n**: Reducci√≥n de overfitting vs Random Forest, buen balance

#### 4. **XGBoost** ‚≠ê (Modelo Final)
```python
import xgboost as xgb

xgb_model = xgb.XGBRegressor(
    objective='reg:squarederror',
    n_estimators=500,
    learning_rate=0.05,
    max_depth=6,
    min_child_weight=3,
    subsample=0.8,
    colsample_bytree=0.8,
    gamma=0.1,
    random_state=42
)

xgb_model.fit(
    X_train, y_train,
    eval_set=[(X_train, y_train), (X_test, y_test)],
    early_stopping_rounds=50,
    verbose=False
)
```

### Optimizaci√≥n de Hiperpar√°metros

Se utiliz√≥ **GridSearchCV** con validaci√≥n cruzada de 5 folds:

```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [300, 500, 700],
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [4, 6, 8],
    'min_child_weight': [1, 3, 5],
    'subsample': [0.7, 0.8, 0.9],
    'colsample_bytree': [0.7, 0.8, 0.9]
}

grid_search = GridSearchCV(
    xgb.XGBRegressor(objective='reg:squarederror', random_state=42),
    param_grid,
    cv=5,
    scoring='neg_mean_squared_error',
    n_jobs=-1,
    verbose=2
)

grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_
```

**Mejores Hiperpar√°metros**:
- `n_estimators`: 500
- `learning_rate`: 0.05
- `max_depth`: 6
- `min_child_weight`: 3
- `subsample`: 0.8
- `colsample_bytree`: 0.8

### M√©tricas del Modelo Final (XGBoost)

| M√©trica | Train | Test |
|---------|-------|------|
| **RMSE** | 0.4766 | 0.4943 |
| **MAE** | 0.3451 | - |
| **R¬≤** | - | 0.6588 |

**An√°lisis de Overfitting**:
```python
overfitting_percentage = (test_rmse - train_rmse) / train_rmse * 100
# = (0.4943 - 0.4766) / 0.4766 * 100 = 3.71%
```

‚úÖ **Overfitting < 5%**: El modelo generaliza bien a datos no vistos

### Importancia de Features

Las 5 variables m√°s influyentes seg√∫n XGBoost:

1. **`model_year`** (25.3%) - Factor principal de depreciaci√≥n
2. **`milage`** (18.7%) - Segundo factor m√°s importante
3. **`brand` (encoded)** (15.2%) - Valor de marca
4. **`model` (encoded)** (12.8%) - Modelo espec√≠fico
5. **`horsepower`** (10.5%) - Potencia del motor

### Guardado del Modelo

```python
joblib.dump(best_model, 'model/best_xgb_model_final.pkl')

# Guardar orden de features para predicci√≥n
feature_order = X_train.columns.tolist()
joblib.dump(feature_order, 'model/feature_order.pkl')

# Guardar m√©tricas
metrics = {
    "model": "XGBoost",
    "train_rmse": float(train_rmse),
    "rmse": float(test_rmse),
    "mae": float(mae),
    "r2": float(r2),
    "target_transformation": "log_or_scaled"
}

import json
with open('metrics.json', 'w') as f:
    json.dump(metrics, f, indent=2)
```

---

## üìä Dashboard Interactivo

La aplicaci√≥n `App.py` proporciona una interfaz web desarrollada con **Streamlit** dividida en tres secciones principales:

### 1. üìä Dashboard Anal√≠tico

**Prop√≥sito**: Explorar visualmente el dataset filtrado con controles interactivos en tiempo real.

#### Filtros del Sidebar

```python
selected_brand = st.multiselect("Marca", options=sorted(df["brand"].unique()))
year_range = st.slider("A√±o del modelo", 2010, 2024, (2010, 2024))
price_range = st.slider("Rango de precio ($)", min_value=int(df["price"].min()), 
                         max_value=int(df["price"].max()))
selected_models = st.multiselect("Modelo", options=sorted(filtered_models))
```

#### KPIs Principales

Muestra m√©tricas clave del subset filtrado:

| KPI | Descripci√≥n | C√°lculo |
|-----|-------------|---------|
| **Precio Medio** | Media aritm√©tica | `df_filtered['price'].mean()` |
| **Precio Mediano** | Valor central | `df_filtered['price'].median()` |
| **N¬∞ Veh√≠culos** | Tama√±o del subset | `len(df_filtered)` |
| **Desviaci√≥n Est√°ndar** | Variabilidad de precios | `df_filtered['price'].std()` |

#### Visualizaciones Incluidas

1. **Histograma de Distribuci√≥n de Precios**
   - Muestra concentraci√≥n de veh√≠culos por rango de precio
   - Formato personalizado del eje X con sufijo 'k' para miles

2. **Scatter Plot: Kilometraje vs Precio**
   - Visualiza correlaci√≥n negativa entre variables
   - Alpha=0.4 para manejar overlapping

3. **Boxplot del Precio**
   - Identifica outliers y cuartiles
   - Orientaci√≥n horizontal para mejor legibilidad

4. **Scatter Plot: A√±o del Modelo vs Precio**
   - Evidencia tendencia positiva temporal
   - √ötil para identificar depreciaci√≥n

**Expandable Insights**: Cada gr√°fica incluye un expander con interpretaci√≥n para usuarios no t√©cnicos.

### 2. üîÆ Predicci√≥n de Precio

**Prop√≥sito**: Permitir al usuario estimar el precio de un veh√≠culo introduciendo sus caracter√≠sticas.

#### Interfaz de Entrada

```python
brand = st.selectbox("Marca", sorted(brand_model_options.keys()))
model_car = st.selectbox("Modelo", sorted(brand_model_options[brand].keys()))
ext_col = st.selectbox("Color exterior", ext_colors)
int_col = st.selectbox("Color interior", int_colors)
model_year = st.number_input("A√±o", 1990, 2024, 2018)
milage = st.number_input("Kilometraje", 0, 500000, 50000)
horsepower = st.number_input("Caballos", 50, 1500, 150)
engine_liters = st.number_input("Litros motor", 0.8, 8.0, 2.0)

# Checkboxes para variables booleanas
turbo = st.checkbox("Turbo")
clean_title = st.checkbox("Clean title (t√≠tulo limpio)")
accident_none = st.checkbox("Accident: None reported")
```

#### Selectores Dependientes

**Innovaci√≥n clave**: Los colores disponibles se filtran din√°micamente seg√∫n marca/modelo seleccionado:

```python
ext_colors = brand_model_options[brand][model_car]["ext_col"]
int_colors = brand_model_options[brand][model_car]["int_col"]

# Fallback si no hay datos espec√≠ficos
if not ext_colors:
    ext_colors = sorted(target_encoding_maps["ext_col"]["mapping"].keys())
```

Esto garantiza que el usuario solo vea opciones **realmente presentes** en el dataset para esa combinaci√≥n espec√≠fica.

#### Pipeline de Predicci√≥n

```python
# 1. Crear DataFrame con input del usuario
input_df = pd.DataFrame([{
    "brand": brand,
    "model": model_car,
    "model_year": model_year,
    # ... resto de features
}])

# 2. Aplicar target encoding usando mapeos guardados
for col, enc in target_encoding_maps.items():
    input_df[col] = input_df[col].map(enc["mapping"]).fillna(enc["global_mean"])

# 3. Reordenar columnas seg√∫n feature_order guardado
input_df = input_df.reindex(columns=feature_order, fill_value=0)

# 4. Predecir (recordar que el modelo predice log-precio)
log_price_pred = model.predict(input_df)[0]
price_pred = np.expm1(log_price_pred)  # Transformaci√≥n inversa

# 5. Mostrar resultado
st.metric("Precio estimado", f"${price_pred:,.0f}")
```

**Manejo de Categor√≠as Nuevas**: Si el usuario introduce valores no presentes en el training set, el sistema usa `global_mean` del target encoding como fallback.

### 3. üìà Rendimiento del Modelo

**Prop√≥sito**: Transparencia total sobre el desempe√±o del modelo para usuarios t√©cnicos.

#### M√©tricas Mostradas

```python
with open("metrics.json", "r") as f:
    metrics = json.load(f)

col1, col2, col3, col4 = st.columns(4)
col1.metric("RMSE Train", f"{metrics['train_rmse']:.4f}")
col2.metric("RMSE Test", f"{metrics['rmse']:.4f}")
col3.metric("MAE", f"{metrics['mae']:.4f}")
col4.metric("R¬≤", f"{metrics['r2']:.4f}")
```

#### An√°lisis de Overfitting

```python
overfitting = (test_rmse - train_rmse) / train_rmse * 100

st.metric(
    "Overfitting (%)",
    f"{overfitting:.2f}%",
    delta="OK" if overfitting < 5 else "Revisar"
)
```

**Interpretaci√≥n Autom√°tica**: El dashboard incluye un bloque de markdown din√°mico que explica:
- Si el modelo presenta sobreajuste aceptable
- Qu√© porcentaje de varianza explica el R¬≤
- Significado del MAE en contexto de negocio

#### Info Box Educativa

```python
st.info(
    "Las m√©tricas se obtuvieron tras validaci√≥n cruzada y optimizaci√≥n del modelo XGBoost, "
    "asegurando una buena capacidad de generalizaci√≥n."
)
```

### Estilizaci√≥n CSS Personalizada

```python
st.markdown("""
<style>
.header {
    text-align: center;
    padding: 1rem;
    background-color: #0e1117;
    border-radius: 10px;
    margin-bottom: 1rem;
}
</style>
""", unsafe_allow_html=True)
```

Proporciona un dise√±o profesional consistente con branding oscuro.

---

## üê≥ Dockerizaci√≥n

El proyecto incluye una containerizaci√≥n completa para garantizar reproducibilidad en cualquier entorno.

### Dockerfile

```dockerfile
FROM python:3.10-slim

WORKDIR /app

# Instalaci√≥n de dependencias
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copia de archivos del proyecto
COPY . .

# Exposici√≥n del puerto de Streamlit
EXPOSE 8501

# Comando de ejecuci√≥n
CMD ["streamlit", "run", "App.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

**Decisiones de dise√±o**:
- ‚úÖ **Imagen base slim**: Reduce tama√±o final del contenedor (~150MB vs 1GB con full Python)
- ‚úÖ **No cache en pip**: Evita almacenar archivos temporales innecesarios
- ‚úÖ **Binding a 0.0.0.0**: Permite acceso desde fuera del contenedor
- ‚úÖ **Puerto 8501**: Puerto est√°ndar de Streamlit

### docker-compose.yml

```yaml
services:
  app:
    build: .
    ports:
      - "8501:8501"
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - .:/app
```

**Caracter√≠sticas**:
- **Port mapping**: Host 8501 ‚Üí Container 8501
- **PYTHONUNBUFFERED**: Logs en tiempo real sin buffering
- **Volume mount**: Permite desarrollo sin rebuild (hot-reload)

### .dockerignore

```
__pycache__/
*.pyc
.git/
.gitignore
README.md
notebooks/
*.ipynb
```

Excluye archivos innecesarios para reducir contexto de build y tama√±o de imagen.

### Comandos de Docker

#### Construcci√≥n de la imagen
```bash
docker-compose build
```

#### Ejecuci√≥n del contenedor
```bash
docker-compose up -d
```
- Flag `-d`: Modo detached (background)

#### Acceso a la aplicaci√≥n
```
http://localhost:8501
```

#### Detener servicios
```bash
docker-compose down
```

#### Ver logs en tiempo real
```bash
docker-compose logs -f app
```

### Ventajas de la Dockerizaci√≥n

1. **Reproducibilidad**: Mismo entorno en desarrollo, staging y producci√≥n
2. **Aislamiento**: No contamina Python del sistema host
3. **Portabilidad**: Funciona en cualquier sistema con Docker
4. **Versionado**: La imagen Docker es inmutable y versionable
5. **Despliegue Simplificado**: Un comando para levantar toda la aplicaci√≥n

---

## üöÄ Instalaci√≥n y Ejecuci√≥n

### Requisitos Previos

- **Python 3.10+** (si ejecuci√≥n local)
- **Docker & Docker Compose** (si ejecuci√≥n containerizada - **recomendado**)
- **Git** para clonar el repositorio

### Opci√≥n A: Ejecuci√≥n con Docker üê≥ (Recomendado)

#### Paso 1: Clonar el repositorio
```bash
git clone https://github.com/Bootcamp-Data-Analyst/Proyecto-Regression-g1.git
cd Proyecto-Regression-g1
```

#### Paso 2: Construir y levantar el contenedor
```bash
docker-compose up --build -d
```

**Explicaci√≥n de flags**:
- `--build`: Fuerza reconstrucci√≥n de imagen (importante en primer uso)
- `-d`: Ejecuta en background (daemon mode)

#### Paso 3: Acceder a la aplicaci√≥n
Abrir navegador en:
```
http://localhost:8501
```

#### Paso 4: Detener la aplicaci√≥n
```bash
docker-compose down
```

**Tiempo estimado**: ~5 minutos (construcci√≥n inicial), ~30 segundos (ejecuciones posteriores)

### Opci√≥n B: Ejecuci√≥n Local (Sin Docker)

#### Paso 1: Clonar el repositorio
```bash
git clone https://github.com/Bootcamp-Data-Analyst/Proyecto-Regression-g1.git
cd Proyecto-Regression-g1
```

#### Paso 2: Crear entorno virtual (recomendado)
```bash
# Linux/Mac
python -m venv venv
source venv/bin/activate

# Windows
python -m venv venv
.\venv\Scripts\activate
```

#### Paso 3: Instalar dependencias
```bash
pip install -r requirements.txt
```

**Nota**: Si hay conflictos de versiones, usar:
```bash
pip install --upgrade pip
pip install -r requirements.txt --upgrade
```

#### Paso 4: Ejecutar la aplicaci√≥n
```bash
streamlit run App.py
```

La aplicaci√≥n se abrir√° autom√°ticamente en el navegador en:
```
http://localhost:8501
```

#### Paso 5: Detener la aplicaci√≥n
Presionar `Ctrl + C` en la terminal

**Tiempo estimado**: ~3 minutos

### Soluci√≥n de Problemas Comunes

| Problema | Soluci√≥n |
|----------|----------|
| **Puerto 8501 ocupado** | Cambiar puerto en `docker-compose.yml`: `"8502:8501"` |
| **Error de permisos en Docker** | Ejecutar con `sudo` (Linux) o verificar Docker Desktop (Windows/Mac) |
| **`ModuleNotFoundError` local** | Verificar activaci√≥n de venv y reinstalar requirements |
| **Dashboard no carga datos** | Verificar presencia de archivos en `data/clean/` y `model/` |

---

## üìà Resultados y Conclusiones

### Logros del Proyecto

#### 1. **Rendimiento del Modelo**

‚úÖ **Objetivo de R¬≤ > 0.60 cumplido**: El modelo alcanz√≥ un **R¬≤ de 0.6588**, explicando el **66% de la variabilidad** en los precios de veh√≠culos usados.

‚úÖ **Overfitting controlado**: Con apenas **3.71% de diferencia** entre RMSE de entrenamiento y test, el modelo demuestra excelente capacidad de generalizaci√≥n.

‚úÖ **Error absoluto aceptable**: Un MAE de 0.3451 en escala logar√≠tmica se traduce en un error medio de ~$4,000-$6,000 en precio real, razonable para la variabilidad del mercado.

#### 2. **Insights de Negocio**

**Factores clave que determinan el precio**:

1. **Depreciaci√≥n temporal** (25% importancia):
   - Veh√≠culos pierden ~15-20% de valor por a√±o en promedio
   - Modelos >10 a√±os experimentan ca√≠da exponencial

2. **Desgaste por uso** (19% importancia):
   - Cada 10,000 millas reduce precio ~$500-$1,000
   - Veh√≠culos con <20,000 millas mantienen "premium del nuevo"

3. **Valor de marca** (15% importancia):
   - Marcas premium (Mercedes, BMW) retienen valor mejor que mainstream
   - Algunas marcas nicho (Tesla) aprecian con el tiempo

4. **Especificaciones t√©cnicas** (11% importancia):
   - Potencia del motor correlaciona con segmento de mercado
   - Veh√≠culos turbo mantienen precio ~8% superior

**Recomendaciones para vendedores**:
- Mantener kilometraje bajo y servicio regular maximiza ROI
- Veh√≠culos con "clean title" valen ~12% m√°s
- Color influye: blanco/negro/gris m√°s demandados que colores ex√≥ticos

**Recomendaciones para compradores**:
- Veh√≠culos de 3-5 a√±os ofrecen mejor relaci√≥n precio/calidad
- Verificar historial de accidentes antes de compra
- Considerar marcas mainstream para mejor depreciaci√≥n lineal

#### 3. **Calidad T√©cnica**

‚úÖ **Pipeline reproducible**: Dockerizaci√≥n permite despliegue en producci√≥n sin modificaciones

‚úÖ **C√≥digo modular**: Separaci√≥n clara entre data cleaning, feature engineering, modeling y deployment

‚úÖ **Manejo robusto de edge cases**: Target encoding con smoothing evita overfitting en categor√≠as raras

### Limitaciones Identificadas

1. **Cobertura geogr√°fica**: Dataset limitado a mercado estadounidense (no generalizable a Europa/Asia)

2. **Variables ausentes**:
   - Estado mec√°nico/est√©tico (solo historial de accidentes)
   - Equipamiento opcional (navegaci√≥n, cuero, techo solar)
   - Localizaci√≥n geogr√°fica (precios var√≠an por estado/ciudad)

3. **Sesgo temporal**: Datos pueden no reflejar fluctuaciones post-pandemia o crisis econ√≥micas

4. **Outliers de lujo**: Modelos de alta gama (>$200k) tienen predicciones menos precisas por falta de datos

### Comparaci√≥n con Benchmarks de la Industria

| M√©trica | Nuestro Modelo | Kelley Blue Book (KBB) | Edmunds |
|---------|----------------|------------------------|---------|
| **R¬≤** | 0.66 | ~0.75* | ~0.72* |
| **MAE** | $4,000-$6,000 | $3,000-$4,500* | $3,500-$5,000* |

*Valores estimados basados en literatura p√∫blica; los modelos comerciales incorporan datos propietarios adicionales

**An√°lisis**: Nuestro modelo alcanza ~88% del rendimiento de soluciones comerciales usando solo features p√∫blicamente disponibles, lo cual es excelente para un proyecto acad√©mico.

---

## üí° Mejoras Futuras

### Corto Plazo (1-3 meses)

#### 1. **Ingenier√≠a de Features Avanzada**
- **Interacciones**: Crear features `brand √ó model_year`, `horsepower / engine_liters` (potencia espec√≠fica)
- **Clustering**: Agrupar veh√≠culos por segmento (sedan, SUV, sports) y usar como feature categ√≥rica
- **Temporal**: Agregar "edad del veh√≠culo" y "depreciation_rate" calculada

#### 2. **Modelos Ensembled**
```python
# Stacking de m√∫ltiples modelos
from sklearn.ensemble import StackingRegressor

estimators = [
    ('xgb', xgb_model),
    ('rf', rf_model),
    ('gb', gb_model)
]

stacked_model = StackingRegressor(
    estimators=estimators,
    final_estimator=LinearRegression()
)
```
**Beneficio esperado**: +2-3% en R¬≤ seg√∫n literatura

#### 3. **Intervalos de Confianza**
Implementar predicci√≥n probabil√≠stica para mostrar:
- "Precio estimado: $25,000 ¬± $3,500 (95% confianza)"

```python
from sklearn.ensemble import GradientBoostingRegressor

gbr = GradientBoostingRegressor(loss='quantile', alpha=0.95)
```

### Medio Plazo (3-6 meses)

#### 4. **Datos Adicionales**
- **APIs externas**: Integrar datos de CarFax, NHTSA (seguridad), EPA (eficiencia)
- **Im√°genes**: CNN para analizar estado visual y estimar reparaciones
- **Web scraping**: Actualizar dataset con anuncios recientes

#### 5. **Dashboards Avanzados**
- **Mapa interactivo**: Visualizar precios por regi√≥n geogr√°fica (Plotly Mapbox)
- **An√°lisis de tendencias**: Time-series de depreciation rate
- **Comparador**: Permitir comparaci√≥n lado-a-lado de 2-3 veh√≠culos

#### 6. **API RESTful**
Exponer el modelo como servicio:

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class CarFeatures(BaseModel):
    brand: str
    model: str
    # ... otras features

@app.post("/predict")
async def predict_price(car: CarFeatures):
    prediction = model.predict(...)
    return {"estimated_price": float(prediction)}
```

**Beneficio**: Permite integraci√≥n con sistemas externos (apps m√≥viles, CRMs)

### Largo Plazo (6-12 meses)

#### 7. **Deep Learning**
Experimentar con redes neuronales:
- **TabNet**: Arquitectura optimizada para datos tabulares
- **Neural Oblivious Decision Ensembles (NODE)**: State-of-the-art en tabular data

#### 8. **AutoML**
Implementar b√∫squeda autom√°tica de modelos:

```python
from autogluon.tabular import TabularPredictor

predictor = TabularPredictor(label='price').fit(
    train_data=df_train,
    time_limit=3600,  # 1 hora
    presets='best_quality'
)
```

#### 9. **Deployment Productivo**
- **CI/CD**: Pipeline autom√°tico con GitHub Actions
- **Monitoreo**: Tracking de model drift con Evidently AI
- **A/B Testing**: Comparar modelos en producci√≥n con m√©tricas de negocio

#### 10. **Explicabilidad**
Implementar **SHAP values** para explicar predicciones individuales:

```python
import shap

explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# Visualizar importancia de features para predicci√≥n espec√≠fica
shap.force_plot(explainer.expected_value, shap_values[0], X_test.iloc[0])
```

**Beneficio**: Transparencia para usuarios (por qu√© el modelo predijo X precio)

### Priorizaci√≥n de Mejoras

| Mejora | Impacto en R¬≤ | Esfuerzo | Prioridad |
|--------|---------------|----------|-----------|
| Feature engineering avanzada | +0.03 | Bajo | üî• Alta |
| Ensemble stacking | +0.02 | Medio | üî• Alta |
| API RESTful | 0 | Bajo | üî• Alta |
| Datos adicionales (APIs) | +0.05 | Alto | ‚ö° Media |
| Deep Learning | +0.02 | Alto | ‚ö° Media |
| SHAP explicabilidad | 0 | Medio | ‚ö° Media |
| AutoML | +0.04 | Muy Alto | ‚ùÑÔ∏è Baja |

---

## üìö Referencias

### Proyecto Base
- **Bootcamp Factor√≠a F5 - Data Analyst**  
  Repositorio original: [DA-Project-Regression](https://github.com/Factoria-F5-madrid/DA-Project-Regression)

### Documentaci√≥n T√©cnica

#### Librer√≠as Utilizadas
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [NumPy Documentation](https://numpy.org/doc/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Docker Documentation](https://docs.docker.com/)

#### Papers y Art√≠culos Acad√©micos
- Chen, T., & Guestrin, C. (2016). *XGBoost: A Scalable Tree Boosting System*. KDD '16.
- Micci-Barreca, D. (2001). *A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems*. SIGKDD.

#### Recursos de Aprendizaje
- [Kaggle Learn - Feature Engineering](https://www.kaggle.com/learn/feature-engineering)
- [Towards Data Science - Target Encoding](https://towardsdatascience.com/dealing-with-categorical-variables-by-using-target-encoder-a0f5d3f68f34)
- [Streamlit Gallery](https://streamlit.io/gallery) - Inspiraci√≥n para dashboards

### Datasets Similares

- **Kaggle**: [Used Car Price Prediction](https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data)
- **UCI ML Repository**: [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/automobile)

---

## üìÑ Licencia

Este proyecto fue desarrollado con fines **educativos** como parte del **Bootcamp de Data Analyst de Factor√≠a F5**.

El c√≥digo y documentaci√≥n est√°n disponibles para:
- ‚úÖ Aprendizaje y referencia personal
- ‚úÖ Uso en portfolios profesionales
- ‚úÖ Fork y adaptaci√≥n con atribuci√≥n apropiada

**Restricciones**:
- ‚ùå Uso comercial sin autorizaci√≥n
- ‚ùå Redistribuci√≥n sin mencionar autor√≠a original

---

## üëè Agradecimientos

- **Factor√≠a F5** por proporcionar el bootcamp y recursos
- **Instructores del programa** por mentor√≠a t√©cnica
- **Comunidad Kaggle/Stack Overflow** por soluciones a desaf√≠os espec√≠ficos
- **Open Source contributors** de Pandas, Scikit-learn, XGBoost y Streamlit

---

## üìß Contacto

¬øPreguntas sobre el proyecto? Contacta al equipo:

- **Ra√∫l R√≠os Moreno**: [LinkedIn](https://www.linkedin.com/in/raul-rios-moreno/)
- **Pablo Rodr√≠guez Mu√±oz**: [LinkedIn](https://www.linkedin.com/in/pablo-rodr√≠guez-mu√±oz-357890185)
- **Mariana Moreno**: [LinkedIn](https://www.linkedin.com/in/mariana-moreno-henao/)

---

<div align="center">

**‚≠ê Si este proyecto te result√≥ √∫til, considera darle una estrella en GitHub ‚≠ê**

![Python](https://img.shields.io/badge/Made%20with-Python-blue?style=for-the-badge&logo=python)
![Streamlit](https://img.shields.io/badge/Powered%20by-Streamlit-red?style=for-the-badge&logo=streamlit)
![Docker](https://img.shields.io/badge/Containerized%20with-Docker-blue?style=for-the-badge&logo=docker)

</div>
