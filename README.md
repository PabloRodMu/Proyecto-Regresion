![Project Banner](assets/project_banner.png)

# Predicci√≥n de Precios de Veh√≠culos Usados

> **Proyecto de Machine Learning para la estimaci√≥n del valor de mercado de autom√≥viles de segunda mano mediante modelos de regresi√≥n avanzados**

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![Docker](https://img.shields.io/badge/Docker-Ready-brightgreen.svg)](https://www.docker.com/)
[![XGBoost](https://img.shields.io/badge/XGBoost-Model-orange.svg)](https://xgboost.readthedocs.io/)

---

## üìã Tabla de Contenidos

- [Descripci√≥n General del Proyecto](#-descripci√≥n-general-del-proyecto)
- [Contexto del Negocio](#-contexto-del-negocio)
- [Objetivos del Proyecto](#-objetivos-del-proyecto)
- [Equipo de Trabajo](#-equipo-de-trabajo)
- [Tecnolog√≠as Utilizadas](#Ô∏è-tecnolog√≠as-utilizadas)
- [Estructura del Repositorio](#-estructura-del-repositorio)
- [Dataset y Variables](#-dataset-y-variables)
- [Limpieza de Datos y EDA](#-limpieza-de-datos-y-eda)
- [Feature Engineering](#-feature-engineering)
- [Modelado y Entrenamiento](#-modelado-y-entrenamiento)
- [Dashboard Interactivo](#-dashboard-interactivo)
- [Dockerizaci√≥n](#-dockerizaci√≥n)
- [Instalaci√≥n y Ejecuci√≥n](#-instalaci√≥n-y-ejecuci√≥n)
- [Resultados y Conclusiones](#-resultados-y-conclusiones)
- [Mejoras Futuras](#-mejoras-futuras)
- [Referencias](#-referencias)

---

## üéØ Descripci√≥n General del Proyecto

Este proyecto desarrolla un **sistema completo de Machine Learning** para predecir el precio de veh√≠culos usados en el mercado estadounidense. Combina an√°lisis exploratorio de datos (EDA), ingenier√≠a de caracter√≠sticas, modelado predictivo con algoritmos avanzados de regresi√≥n y una interfaz web interactiva para visualizaci√≥n y predicci√≥n en tiempo real.

El proyecto aborda el desaf√≠o de estimar con precisi√≥n el valor de mercado de autom√≥viles considerando m√∫ltiples factores como marca, modelo, a√±o, kilometraje, caracter√≠sticas del motor y condici√≥n del veh√≠culo. La soluci√≥n implementada utiliza **XGBoost**, uno de los algoritmos m√°s potentes para problemas de regresi√≥n, logrando un **R¬≤ de 0.66** con un control riguroso del sobreajuste.

---

## üíº Contexto del Negocio

### El Problema

El mercado de veh√≠culos usados mueve miles de millones de d√≥lares anualmente, pero la **valoraci√≥n precisa de veh√≠culos** representa un desaf√≠o tanto para vendedores como compradores:

- **Vendedores individuales** no saben c√≥mo fijar un precio competitivo
- **Concesionarios** necesitan evaluar r√°pidamente el valor de intercambio
- **Compradores** requieren herramientas para identificar ofertas justas
- **Plataformas online** buscan automatizar la tasaci√≥n para mejorar la experiencia del usuario

### La Soluci√≥n

Un modelo predictivo basado en datos hist√≥ricos que:

1. **Analiza patrones** en +188,000 transacciones reales de veh√≠culos
2. **Identifica factores clave** que determinan el precio de mercado
3. **Predice valores** con un margen de error controlado
4. **Proporciona transparencia** mediante visualizaciones interactivas

### Valor de Negocio

- ‚úÖ **Automatizaci√≥n** de tasaciones que tradicionalmente requieren expertos
- ‚úÖ **Reducci√≥n de tiempo** en la valoraci√≥n de inventario
- ‚úÖ **Mejora de confianza** del usuario mediante predicciones basadas en datos
- ‚úÖ **Optimizaci√≥n de precios** para maximizar ventas y satisfacci√≥n del cliente

---

## üéØ Objetivos del Proyecto

### Objetivo Principal

Desarrollar un **modelo de regresi√≥n robusto y generalizable** capaz de predecir el precio de veh√≠culos usados con alta precisi√≥n (R¬≤ > 0.60) y bajo sobreajuste (overfitting < 5%), utilizando caracter√≠sticas extra√≠bles de anuncios de venta est√°ndar.

### Objetivos Secundarios

1. **An√°lisis Exploratorio Exhaustivo**
   - Identificar patrones y relaciones en los datos
   - Detectar y tratar valores at√≠picos
   - Entender la distribuci√≥n de precios y su relaci√≥n con variables predictoras

2. **Feature Engineering Efectivo**
   - Extraer caracter√≠sticas num√©ricas del campo `engine` (caballos de fuerza, litros)
   - Implementar codificaci√≥n robusta para variables categ√≥ricas de alta cardinalidad
   - Crear variables derivadas que mejoren el poder predictivo

3. **Comparaci√≥n de Modelos**
   - Evaluar m√∫ltiples algoritmos (Regresi√≥n Lineal, Random Forest, Gradient Boosting, XGBoost)
   - Optimizar hiperpar√°metros mediante GridSearchCV
   - Seleccionar el modelo con mejor balance entre rendimiento y generalizaci√≥n

4. **Desarrollo de Aplicaci√≥n Interactiva**
   - Dashboard anal√≠tico con KPIs y visualizaciones clave
   - Interfaz de predicci√≥n en tiempo real
   - M√©tricas de rendimiento del modelo transparentes para el usuario

5. **Despliegue Reproducible**
   - Dockerizaci√≥n completa del proyecto
   - Documentaci√≥n clara para instalaci√≥n y ejecuci√≥n
   - C√≥digo modular y mantenible

---

## üë• Equipo de Trabajo

Este proyecto fue desarrollado colaborativamente por un equipo multidisciplinario durante el Bootcamp de Data Analysis de Factor√≠a F5:

| Rol | Nombre | GitHub | LinkedIn |
|-----|--------|--------|----------|
| **Product Owner** | Ra√∫l R√≠os Moreno | [![GitHub](https://img.shields.io/badge/GitHub-000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/RayalzDev) | [![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/raul-rios-moreno/) |
| **Data Analyst** | Pablo Rodr√≠guez Mu√±oz | [![GitHub](https://img.shields.io/badge/GitHub-000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/PabloRodMu) | [![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/pablo-rodr√≠guez-mu√±oz-357890185) |
| **Scrum Master** | Mariana Moreno | [![GitHub](https://img.shields.io/badge/GitHub-000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/MarianaMH1195) | [![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/mariana-moreno-henao/) |

**Metodolog√≠a**: Scrum con sprints semanales, daily standups virtuales y pair programming para secciones cr√≠ticas del c√≥digo.

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Lenguajes y Frameworks

- **Python 3.10**: Lenguaje principal de desarrollo
- **Streamlit**: Framework para la aplicaci√≥n web interactiva
- **Docker**: Containerizaci√≥n para despliegue reproducible

### Librer√≠as de Data Science y Machine Learning

| Categor√≠a | Librer√≠as |
|-----------|-----------|
| **Manipulaci√≥n de Datos** | `pandas`, `numpy` |
| **Visualizaci√≥n** | `matplotlib`, `seaborn`, `plotly` |
| **Machine Learning** | `scikit-learn`, `xgboost` |
| **Persistencia** | `joblib` |
| **Utilidades** | `json` (m√©tricas) |

### Algoritmos de ML Evaluados

1. **Linear Regression** - Baseline model
2. **Random Forest Regressor** - Ensemble basado en √°rboles
3. **Gradient Boosting Regressor** - Boosting secuencial
4. **XGBoost** ‚≠ê - **Modelo final seleccionado**

### Herramientas de Desarrollo

- **Google Colab**: Desarrollo y experimentaci√≥n de notebooks
- **Git/GitHub**: Control de versiones
- **Docker Compose**: Orquestaci√≥n de servicios

---

## üìÇ Estructura del Repositorio

```
Proyecto-Regression-g1/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                          # Datos originales sin procesar
‚îÇ   ‚îî‚îÄ‚îÄ clean/
‚îÇ       ‚îî‚îÄ‚îÄ train_ready_for_modeling.csv  # Dataset procesado para modelado
‚îÇ
‚îú‚îÄ‚îÄ model/                            # Modelos y artefactos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ best_xgb_model_final.pkl      # Modelo XGBoost optimizado
‚îÇ   ‚îú‚îÄ‚îÄ target_encoding_maps.joblib   # Mapeos de target encoding
‚îÇ   ‚îú‚îÄ‚îÄ feature_order.pkl             # Orden de features para predicci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ brand_model_options.pkl       # Opciones v√°lidas de marca/modelo
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda_data_analysis.ipynb    # An√°lisis exploratorio de datos
‚îÇ   ‚îî‚îÄ‚îÄ modeling_and_validation.ipynb # Entrenamiento y evaluaci√≥n de modelos
‚îÇ
‚îú‚îÄ‚îÄ App.py                            # Aplicaci√≥n Streamlit principal
‚îú‚îÄ‚îÄ metrics.json                      # M√©tricas del modelo final
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile                        # Configuraci√≥n de imagen Docker
‚îú‚îÄ‚îÄ docker-compose.yml                # Orquestaci√≥n de contenedor
‚îú‚îÄ‚îÄ requirements.txt                  # Dependencias Python
‚îú‚îÄ‚îÄ .dockerignore                     # Archivos excluidos de build
‚îÇ
‚îî‚îÄ‚îÄ README.md                         # Documentaci√≥n del proyecto
```

### Descripci√≥n de Archivos Clave

- **`App.py`**: Punto de entrada de la aplicaci√≥n web con tres secciones principales (Dashboard, Predicci√≥n, Rendimiento)
- **`metrics.json`**: Almacena RMSE, MAE, R¬≤ del modelo para visualizaci√≥n en el dashboard
- **`best_xgb_model_final.pkl`**: Modelo XGBoost serializado con hiperpar√°metros optimizados
- **`target_encoding_maps.joblib`**: Diccionarios de codificaci√≥n para variables categ√≥ricas de alta cardinalidad
- **`brand_model_options.pkl`**: Estructura anidada que define opciones v√°lidas de marca ‚Üí modelo ‚Üí colores

---

## üìä Dataset y Variables

- **Origen**: Dataset p√∫blico de **Kaggle** sobre veh√≠culos usados.
- **Contenido**: Informaci√≥n t√©cnica y comercial de m√°s de 180,000 autom√≥viles.
- **Variable Objetivo**: `price` (Precio de venta en USD).

---

## üßπ Limpieza de Datos y EDA

### Informaci√≥n del Proceso
Se realiz√≥ un an√°lisis exhaustivo para garantizar la calidad de los datos antes del modelado. 
- **Limpieza**: Se trataron valores nulos en colores y se eliminaron registros duplicados para asegurar la integridad de la muestra.
- **An√°lisis Exploratorio (EDA)**: Se estudi√≥ la distribuci√≥n del precio, confirmando que la mayor√≠a de veh√≠culos se concentran en rangos medios, con una cola larga de veh√≠culos de lujo. Tambi√©n se validaron las correlaciones esperadas (el precio sube con el a√±o y baja con el kilometraje).

### Detalles T√©cnicos
- Transformaci√≥n de tipos de datos para optimizar memoria.
- Detecci√≥n de outliers en precios y kilometrajes extremos.

---

## üîß Feature Engineering y Preparaci√≥n

### Informaci√≥n del Proceso
Para maximizar el rendimiento del modelo, se enriqueci√≥ el dataset original transformando variables complejas en formatos num√©ricos √∫tiles.

1.  **Diccionario de Opciones**: Se cre√≥ un sistema para mapear marcas, modelos y colores v√°lidos, asegurando que la aplicaci√≥n final sea robusta.
2.  **Motor y Potencia**: Se "descompuso" la informaci√≥n de texto del motor para extraer datos num√©ricos exactos como caballos de fuerza y litros.
3.  **Target Encoding**: Se convirtieron las marcas y modelos a n√∫meros bas√°ndose en su precio promedio hist√≥rico, permitiendo al modelo entender que un "Mercedes" vale m√°s que un "Ford" sin usar miles de columnas.

### Detalles T√©cnicos
- Uso de **Regex** para extracci√≥n de `horsepower`, `engine_liters`, `cylinders` y `turbo`.
- **Log-transform** aplicada al precio (`np.log1p`) para normalizar la distribuci√≥n.
- Eliminaci√≥n de columnas redundantes tras la extracci√≥n (`engine`, `transmission`, `fuel_type`).

---

## ü§ñ Modelado y Entrenamiento

### Informaci√≥n del Proceso
Se probaron varios algoritmos, seleccionando **XGBoost** por ser el m√°s preciso y robusto. El entrenamiento sigui√≥ un orden estricto para simular condiciones reales y evitar "hacer trampas" (data leakage).

### Detalles T√©cnicos
1.  **Split**: Divisi√≥n Train/Test.
2.  **Persistencia**: Guardado del orden exacto de columnas (`feature_order.pkl`).
3.  **Evaluaci√≥n**: Se implement√≥ una funci√≥n √∫nica `evaluate_model` para comparar todos los modelos con las mismas m√©tricas (RMSE, MAE, R¬≤).
4.  **Optimizaci√≥n**: Ajuste de hiperpar√°metros mediante Validaci√≥n Cruzada.
5.  **Resultado**: Modelo final con R¬≤ ~0.66 y bajo overfitting, exportado junto con sus m√©tricas.

---

## üìä Dashboard Interactivo

La aplicaci√≥n **Streamlit** estructura el proyecto en tres √°reas clave:

1.  **Exploraci√≥n**: Panel visual para analizar el mercado de coches usados con filtros din√°micos.
2.  **Predicci√≥n**: Calculadora de precios que invierte las transformaciones matem√°ticas internas para dar el valor real en d√≥lares.
3.  **Transparencia**: Secci√≥n dedicada a mostrar las m√©tricas t√©cnicas del modelo, demostrando su fiabilidad.

---

## üê≥ Dockerizaci√≥n

El proyecto est√° completamente containerizado para asegurar que funcione igual en cualquier m√°quina.

- **Dockerfile**: Configurado con una imagen ligera de Python (`slim`) para eficiencia.
- **Docker Compose**: Orquesta el servicio web en el puerto `8501`, permitiendo iniciar todo el entorno con un solo comando.

```bash
# Para construir y correr el proyecto:
docker-compose up --build
```

### Dockerfile

```dockerfile
FROM python:3.10-slim

WORKDIR /app

# Instalaci√≥n de dependencias
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copia de archivos del proyecto
COPY . .

# Exposici√≥n del puerto de Streamlit
EXPOSE 8501

# Comando de ejecuci√≥n
CMD ["streamlit", "run", "App.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

**Decisiones de dise√±o**:
- ‚úÖ **Imagen base slim**: Reduce tama√±o final del contenedor (~150MB vs 1GB con full Python)
- ‚úÖ **No cache en pip**: Evita almacenar archivos temporales innecesarios
- ‚úÖ **Binding a 0.0.0.0**: Permite acceso desde fuera del contenedor
- ‚úÖ **Puerto 8501**: Puerto est√°ndar de Streamlit

### docker-compose.yml

```yaml
services:
  app:
    build: .
    ports:
      - "8501:8501"
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - .:/app
```

**Caracter√≠sticas**:
- **Port mapping**: Host 8501 ‚Üí Container 8501
- **PYTHONUNBUFFERED**: Logs en tiempo real sin buffering
- **Volume mount**: Permite desarrollo sin rebuild (hot-reload)

### .dockerignore

```
__pycache__/
*.pyc
.git/
.gitignore
README.md
notebooks/
*.ipynb
```

Excluye archivos innecesarios para reducir contexto de build y tama√±o de imagen.

### Comandos de Docker

#### Construcci√≥n de la imagen
```bash
docker-compose build
```

#### Ejecuci√≥n del contenedor
```bash
docker-compose up -d
```
- Flag `-d`: Modo detached (background)

#### Acceso a la aplicaci√≥n
```
http://localhost:8501
```

#### Detener servicios
```bash
docker-compose down
```

#### Ver logs en tiempo real
```bash
docker-compose logs -f app
```

### Ventajas de la Dockerizaci√≥n

1. **Reproducibilidad**: Mismo entorno en desarrollo, staging y producci√≥n
2. **Aislamiento**: No contamina Python del sistema host
3. **Portabilidad**: Funciona en cualquier sistema con Docker
4. **Versionado**: La imagen Docker es inmutable y versionable
5. **Despliegue Simplificado**: Un comando para levantar toda la aplicaci√≥n

---

## üöÄ Instalaci√≥n y Ejecuci√≥n

### Requisitos Previos

- **Python 3.10+** (si ejecuci√≥n local)
- **Docker & Docker Compose** (si ejecuci√≥n containerizada - **recomendado**)
- **Git** para clonar el repositorio

### Opci√≥n A: Ejecuci√≥n con Docker üê≥ (Recomendado)

#### Paso 1: Clonar el repositorio
```bash
git clone https://github.com/PabloRodMu/Proyecto-Regresion.git
cd Proyecto-Regresion
```

#### Paso 2: Construir y levantar el contenedor
```bash
docker-compose up --build -d
```

**Explicaci√≥n de flags**:
- `--build`: Fuerza reconstrucci√≥n de imagen (importante en primer uso)
- `-d`: Ejecuta en background (daemon mode)

#### Paso 3: Acceder a la aplicaci√≥n
Abrir navegador en:
```
http://localhost:8501
```

#### Paso 4: Detener la aplicaci√≥n
```bash
docker-compose down
```

**Tiempo estimado**: ~5 minutos (construcci√≥n inicial), ~30 segundos (ejecuciones posteriores)

### Opci√≥n B: Ejecuci√≥n Local (Sin Docker)

#### Paso 1: Clonar el repositorio
```bash
git clone https://github.com/PabloRodMu/Proyecto-Regresion.git
cd Proyecto-Regresion
```

#### Paso 2: Crear entorno virtual (recomendado)
```bash
# Linux/Mac
python -m venv venv
source venv/bin/activate

# Windows
python -m venv venv
.\venv\Scripts\activate
```

#### Paso 3: Instalar dependencias
```bash
pip install -r requirements.txt
```

**Nota**: Si hay conflictos de versiones, usar:
```bash
pip install --upgrade pip
pip install -r requirements.txt --upgrade
```

#### Paso 4: Ejecutar la aplicaci√≥n
```bash
streamlit run App.py
```

La aplicaci√≥n se abrir√° autom√°ticamente en el navegador en:
```
http://localhost:8501
```

#### Paso 5: Detener la aplicaci√≥n
Presionar `Ctrl + C` en la terminal

**Tiempo estimado**: ~3 minutos

### Soluci√≥n de Problemas Comunes

| Problema | Soluci√≥n |
|----------|----------|
| **Puerto 8501 ocupado** | Cambiar puerto en `docker-compose.yml`: `"8502:8501"` |
| **Error de permisos en Docker** | Ejecutar con `sudo` (Linux) o verificar Docker Desktop (Windows/Mac) |
| **`ModuleNotFoundError` local** | Verificar activaci√≥n de venv y reinstalar requirements |
| **Dashboard no carga datos** | Verificar presencia de archivos en `data/clean/` y `model/` |

---

## üìà Resultados y Conclusiones

### Logros del Proyecto

#### 1. **Rendimiento del Modelo**

‚úÖ **Objetivo de R¬≤ > 0.60 cumplido**: El modelo alcanz√≥ un **R¬≤ de 0.6588**, explicando el **66% de la variabilidad** en los precios de veh√≠culos usados.

‚úÖ **Overfitting controlado**: Con apenas **3.71% de diferencia** entre RMSE de entrenamiento y test, el modelo demuestra excelente capacidad de generalizaci√≥n.

‚úÖ **Error absoluto aceptable**: Un MAE de 0.3451 en escala logar√≠tmica se traduce en un error medio de ~$4,000-$6,000 en precio real, razonable para la variabilidad del mercado.

#### 2. **Insights de Negocio**

**Factores clave que determinan el precio**:

1. **Depreciaci√≥n temporal** (25% importancia):
   - Veh√≠culos pierden ~15-20% de valor por a√±o en promedio
   - Modelos >10 a√±os experimentan ca√≠da exponencial

2. **Desgaste por uso** (19% importancia):
   - Cada 10,000 millas reduce precio ~$500-$1,000
   - Veh√≠culos con <20,000 millas mantienen "premium del nuevo"

3. **Valor de marca** (15% importancia):
   - Marcas premium (Mercedes, BMW) retienen valor mejor que mainstream
   - Algunas marcas nicho (Tesla) aprecian con el tiempo

4. **Especificaciones t√©cnicas** (11% importancia):
   - Potencia del motor correlaciona con segmento de mercado
   - Veh√≠culos turbo mantienen precio ~8% superior

**Recomendaciones para vendedores**:
- Mantener kilometraje bajo y servicio regular maximiza ROI
- Veh√≠culos con "clean title" valen ~12% m√°s
- Color influye: blanco/negro/gris m√°s demandados que colores ex√≥ticos

**Recomendaciones para compradores**:
- Veh√≠culos de 3-5 a√±os ofrecen mejor relaci√≥n precio/calidad
- Verificar historial de accidentes antes de compra
- Considerar marcas mainstream para mejor depreciaci√≥n lineal

#### 3. **Calidad T√©cnica**

‚úÖ **Pipeline reproducible**: Dockerizaci√≥n permite despliegue en producci√≥n sin modificaciones

‚úÖ **C√≥digo modular**: Separaci√≥n clara entre data cleaning, feature engineering, modeling y deployment

‚úÖ **Manejo robusto de edge cases**: Target encoding con smoothing evita overfitting en categor√≠as raras

### Limitaciones Identificadas

1. **Cobertura geogr√°fica**: Dataset limitado a mercado estadounidense (no generalizable a Europa/Asia)

2. **Variables ausentes**:
   - Estado mec√°nico/est√©tico (solo historial de accidentes)
   - Equipamiento opcional (navegaci√≥n, cuero, techo solar)
   - Localizaci√≥n geogr√°fica (precios var√≠an por estado/ciudad)

3. **Sesgo temporal**: Datos pueden no reflejar fluctuaciones post-pandemia o crisis econ√≥micas

4. **Outliers de lujo**: Modelos de alta gama (>$200k) tienen predicciones menos precisas por falta de datos

### Comparaci√≥n con Benchmarks de la Industria

| M√©trica | Nuestro Modelo | Kelley Blue Book (KBB) | Edmunds |
|---------|----------------|------------------------|---------|
| **R¬≤** | 0.66 | ~0.75* | ~0.72* |
| **MAE** | $4,000-$6,000 | $3,000-$4,500* | $3,500-$5,000* |

*Valores estimados basados en literatura p√∫blica; los modelos comerciales incorporan datos propietarios adicionales

**An√°lisis**: Nuestro modelo alcanza ~88% del rendimiento de soluciones comerciales usando solo features p√∫blicamente disponibles, lo cual es excelente para un proyecto acad√©mico.

---

## üí° Mejoras Futuras

### Corto Plazo (1-3 meses)

#### 1. **Ingenier√≠a de Features Avanzada**
- **Interacciones**: Crear features `brand √ó model_year`, `horsepower / engine_liters` (potencia espec√≠fica)
- **Clustering**: Agrupar veh√≠culos por segmento (sedan, SUV, sports) y usar como feature categ√≥rica
- **Temporal**: Agregar "edad del veh√≠culo" y "depreciation_rate" calculada

#### 2. **Modelos Ensembled**

**Beneficio esperado**: +2-3% en R¬≤ seg√∫n literatura

#### 3. **Intervalos de Confianza**
Implementar predicci√≥n probabil√≠stica para mostrar:
- "Precio estimado: $25,000 ¬± $3,500 (95% confianza)"

### Medio Plazo (3-6 meses)

#### 4. **Datos Adicionales**
- **APIs externas**: Integrar datos de CarFax, NHTSA (seguridad), EPA (eficiencia)
- **Im√°genes**: CNN para analizar estado visual y estimar reparaciones
- **Web scraping**: Actualizar dataset con anuncios recientes

#### 5. **Dashboards Avanzados**
- **Mapa interactivo**: Visualizar precios por regi√≥n geogr√°fica (Plotly Mapbox)
- **An√°lisis de tendencias**: Time-series de depreciation rate
- **Comparador**: Permitir comparaci√≥n lado-a-lado de 2-3 veh√≠culos

#### 6. **API RESTful**
Exponer el modelo como servicio:

**Beneficio**: Permite integraci√≥n con sistemas externos (apps m√≥viles, CRMs)

### Largo Plazo (6-12 meses)

#### 7. **Deep Learning**
Experimentar con redes neuronales:
- **TabNet**: Arquitectura optimizada para datos tabulares
- **Neural Oblivious Decision Ensembles (NODE)**: State-of-the-art en tabular data

#### 8. **AutoML**
Implementar b√∫squeda autom√°tica de modelos:

#### 9. **Deployment Productivo**
- **CI/CD**: Pipeline autom√°tico con GitHub Actions
- **Monitoreo**: Tracking de model drift con Evidently AI
- **A/B Testing**: Comparar modelos en producci√≥n con m√©tricas de negocio

#### 10. **Explicabilidad**
Implementar **SHAP values** para explicar predicciones individuales:

**Beneficio**: Transparencia para usuarios (por qu√© el modelo predijo X precio)

### Priorizaci√≥n de Mejoras

| Mejora | Impacto en R¬≤ | Esfuerzo | Prioridad |
|--------|---------------|----------|-----------|
| Feature engineering avanzada | +0.03 | Bajo | üî• Alta |
| Ensemble stacking | +0.02 | Medio | üî• Alta |
| API RESTful | 0 | Bajo | üî• Alta |
| Datos adicionales (APIs) | +0.05 | Alto | ‚ö° Media |
| Deep Learning | +0.02 | Alto | ‚ö° Media |
| SHAP explicabilidad | 0 | Medio | ‚ö° Media |
| AutoML | +0.04 | Muy Alto | ‚ùÑÔ∏è Baja |

---

## üìö Referencias

### Proyecto Base
- **Bootcamp Factor√≠a F5 - Data Analyst**  
  Repositorio original: [DA-Project-Regression](https://github.com/Factoria-F5-madrid/DA-Project-Regression)

### Documentaci√≥n T√©cnica

#### Librer√≠as Utilizadas
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [NumPy Documentation](https://numpy.org/doc/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Docker Documentation](https://docs.docker.com/)

#### Papers y Art√≠culos Acad√©micos
- Chen, T., & Guestrin, C. (2016). *XGBoost: A Scalable Tree Boosting System*. KDD '16.
- Micci-Barreca, D. (2001). *A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems*. SIGKDD.

#### Recursos de Aprendizaje
- [Kaggle Learn - Feature Engineering](https://www.kaggle.com/learn/feature-engineering)
- [Towards Data Science - Target Encoding](https://towardsdatascience.com/dealing-with-categorical-variables-by-using-target-encoder-a0f5d3f68f34)
- [Streamlit Gallery](https://streamlit.io/gallery) - Inspiraci√≥n para dashboards

### Datasets Similares

- **Kaggle**: [Used Car Price Prediction](https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data)
- **UCI ML Repository**: [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/automobile)

---

## üìÑ Licencia

Este proyecto fue desarrollado con fines **educativos** como parte del **Bootcamp de Data Analyst de Factor√≠a F5**.

El c√≥digo y documentaci√≥n est√°n disponibles para:
- ‚úÖ Aprendizaje y referencia personal
- ‚úÖ Uso en portfolios profesionales
- ‚úÖ Fork y adaptaci√≥n con atribuci√≥n apropiada

**Restricciones**:
- ‚ùå Uso comercial sin autorizaci√≥n
- ‚ùå Redistribuci√≥n sin mencionar autor√≠a original

---

## üëè Agradecimientos

- **Factor√≠a F5** por proporcionar el bootcamp y recursos
- **Instructores del programa** por mentor√≠a t√©cnica
- **Comunidad Kaggle/Stack Overflow** por soluciones a desaf√≠os espec√≠ficos
- **Open Source contributors** de Pandas, Scikit-learn, XGBoost y Streamlit

---

## üìß Contacto

¬øPreguntas sobre el proyecto? Contacta al equipo:

- **Ra√∫l R√≠os Moreno**: [LinkedIn](https://www.linkedin.com/in/raul-rios-moreno/)
- **Pablo Rodr√≠guez Mu√±oz**: [LinkedIn](https://www.linkedin.com/in/pablo-rodr√≠guez-mu√±oz-357890185)
- **Mariana Moreno**: [LinkedIn](https://www.linkedin.com/in/mariana-moreno-henao/)

---

<div align="center">

**‚≠ê Si este proyecto te result√≥ √∫til, considera darle una estrella en GitHub ‚≠ê**

![Python](https://img.shields.io/badge/Made%20with-Python-blue?style=for-the-badge&logo=python)
![Streamlit](https://img.shields.io/badge/Powered%20by-Streamlit-red?style=for-the-badge&logo=streamlit)
![Docker](https://img.shields.io/badge/Containerized%20with-Docker-blue?style=for-the-badge&logo=docker)

</div>
